#+SEQ_TODO: MAYBE TODO IN_PROGRESS | DONE

* CSG

** Boundary conditions
    We maintain the main *invariant of algorithm* that no particle may
    get inside the body deeper than v*dt.

    Body is a recursive composition of primitives or other bodies.

    For primitives, we construct the trace by substituting an equation
    of ray into the surface equation, obtaining times when particle
    hits the surface.

    For compositions, we combine traces from leaves using the
    composition operator.

*** TODO [1/2] Issues
    - [ ] For concave objects, particle may end up inside the body
      after reflection.

      *Solution*: sample next possible reflection for remaining dt.

    - [X] t may be in [-dt;0] even if particle is *outside* the body.

      This _happens_ if particle travels *exactly* dt from its original
      position to body hit. Then on the next step it will move inside
      for dt, and reflection will return it to hit point.

      *Solution*: this is possible, but is obviously improbable, so we
      don't bother.

    - [ ] when b is the intersection of b1 and b2, and ray is parallel
      to the surface of b1, trace used to be considered empty. This
      was fixed for plane, but not for cylinder. We don't care for
      DSMC, since that case is improbable, but may lead to wrong
      results when raycasting for graphical output.

**** TODO [1/2] New bodies
     - [X] cone
     - [ ] parabole

*** Possible improvements
    - use bounding box for body to test collisions first;
    - use octree-based space partitioning scheme;

** Body rendering
*** Ray casting
    
    Use Gloss, which uses REPA under the hood.

*** Implement marching Cubes
         
*** Third party libraries
   - http://opencsg.org/ — CSG rendering;
   - http://www.openscad.org/ — CSG-modeling;
   - http://gts.sourceforge.net/ — GNU Triangulated Surface;
     

** Interface
   DSMC.Traceables.Parser module provides interface to define complex
   bodies using simple textual format inspired by that used in Netgen.

   Primitive constructors provided by Traceables and those recognized
   by Parser are slightly different. Half-space and sphere primitive
   are the same (half-space constructor is named `plane`). For
   cylinder and cone, Traceables provides infinite volumes as well as
   frustums, while Parser provides only frustums (though calling them
   simply `cylinder` and `cone`). Netgen used (badly broken) conical
   frustum but along with infinite cylinder. We use frustums for
   consistency, and it's hard to work with infinite versions for end
   user anyways.

* IN_PROGRESS Macroscopic sampling

** Cell sorting
   (used for collision sampling as well)

   В каждой ячейке может быть разное количество частиц, поэтому для
   использования Repa или Accelerate придётся дополнить разреженную матрицу до
   плотной по самой жирной ячейке. Можно оказаться без памяти (в
   худшем (невероятном) случае N=1e6, Nc=1000 и имеем 1e9 элементов
   массива — память треснет).

   С репой можно было бы вычисление макропараметров делать как
   свёртка по внутреннему измерению. А так придётся parMap.

   Вместо разреженной матрицы из `V.Vector (VU.Vector Particle)`
   используем плотную упаковку ячеек друг за другом в одном большом
   массиве `VU.Vector Particle`. Тесты показывают, что дольше всего
   выполняется копирование частиц в итоговый отсортированный массив.
   Поэтому целесообразно это копирование делать параллельно с помощью
   computeP + fromFunction. Для этого нужно знать положение каждой
   частицы в целевом массиве, для чего:

   1. нужно сначала классифицировать все частицы (параллельно) —
      classes
   
   2. рассчитать количество частиц в каждой ячейке и положения частиц
      в ячейках (последовательно) — lengths и posns

   3. использовать эту информацию для определения смещений
      (последовательно) первого элемента каждой ячейке в итоговом
      массиве (первого индекса ячейки в нём) — starts

   4. зная смещения ячеек и номер частицы в ячейке, можно определить
      точное положение частицы в финальном массиве и построить
      обратный индекс (последовательно) — sortedIds

   5. Дальше копирование (параллельно).

   Тесты показывают, что на 6КК частиц и 64К ячеек при параллельном
   копировании суммарное времени работы sortParticles составляет
   ~0.6s против старого результата ~1.4s при последовательном
   копировании.

   starts не забываем (чтобы знать, где какая ячейка начинается в
   большом массиве).

   Параллельная классификация даёт прироста производительности: 0.04s
   против 0.15s (по времени работы classifyAll — но тут нужно учесть,
   что реповая классификация только вычисляет индексы, а
   последовательная при этом ещё и смещения сразу определяет).

** Типы
  http://www.haskell.org/haskellwiki/Performance/Datatypes   
*** DONE Быстрые вектора
    CLOSED: [2012-06-06 Ср. 21:29]
    Строгие типы + unboxing

    Для Unbox a использовали Tuple (со своим строгим вектором
    получается <<loop>>?). С одной стороны, Unbox. С другой стороны,
    не будет ли ребоксинга на листочках?

    A single-constructor datatype can be unpacked when it is passed to
    a strict function.
    
    Роман сказал, что следует надеяться на GHC и отсутствие
    ребоксинга.
*** MAYBE Traceables
    - improve uniteTraces & intersectTraces
      
    - a different type for HitSegment? Not tuples but custom datatype
      with unboxed values. — как и для векторов
** MAYBE -optc-ffast-math
   Can't use straight away now since we use infinityP/infinityN
** IN_PROGRESS Export lists

   For best results, use an explicit export list. If you do, GHC can
   inline any non-exported functions that are only called once, even
   if they are very big. Without an explicit export list, GHC must
   assume that every function is exported, and hence (to avoid code
   bloat) is more conservative about inlining.

* Optimization
  http://www.haskell.org/haskellwiki/Performance/GHC

** TODO [0/1] Fast calling convention
   - [ ] Classifier is passed as an argument to sortParticles; that
     rules out fast calling convention?

     measured 23.07 1KK@64K — no profit
* Parallelism
** TODO Stochastic parallelism
*** Curent approach
    
    parMapST & splitParMapST

**** TODO [/] Problems
     - [ ] What if task is sufficiently small to have less possible
       chunks than number of seeds available?

*** Possible solutions
    1. Split & Combine typeclasses for containers with data which may
       be splitted, processed in parallel using given seeds, and then
       combined back together. Somehow we need to enforce split &
       combine coherence for Split and Combine instances (perhaps by
       creating a class which would establish a contract both for
       splitting the source data and combining the results).

       This doesn't help for openBoundaryInjection case, when source
       data is always splitted in 6 subchunks (more complex
       partitioning schemes will hardly be efficient or more
       convenient).

    2. Repa may be extended to include Stochastic hints which would
       allow to perform stochastic mapping (perhaps in special monad
       which keeps track of seeds being used for sampling). We need to
       somehow get ace
** MAYBE injection || macroscopic sampling
   Boundary injection is currently hardwired to use maximum of 6
   threads (for each of interface domains). On 4-core system this
   leads to 2 threads waiting for last two domains after first 4
   domains are finished. This time may be used to sample macroscopic
   parameters from the previous step instead!

** TODO Repa unsafe
   Use unbounded Repa combinators
  
** MAYBE LinearSplit
   http://hackage.haskell.org/package/LinearSplit

   May be linked with Control.Parallel.Stochastic to perform load
   balancing.
** MAYBE reducers

   http://hackage.haskell.org/package/reducers

   How to let (Reducer c m) know that we're building with rpar in Eval
   monad?
* Other issues

* Collision logic

  Follow the MSF scheme.

  Average frequency over all collisional pairs is given for reference only.
  In real world implementation, define some sufficiently large number s_max,
  then every collision between two particles with relative velocity c_r and
  collision cross-section ccs_t is accepted with probability (c_r * ccs_t) / (s_max).

  Total number of collisions K_max in every cell follows Poisson
  distribution. However, instead we can sample time intervals between
  collisions (tau) according to inverse-exponential law:

  df(tau) = N*(N-1)/2*s_max*exp(-tau*s_max*((N-1)*N/2))*d(tau).
